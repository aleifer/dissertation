%!TEX root = /Users/andy/Documents/Academics/Dissertation/thesis.tex
%
% https://github.com/downloads/aleifer/dissertation/thesis.pdf

\begin{savequote}[75mm] 
This is some random quote to start off the chapter.
\qauthor{Firstname lastname} 
\end{savequote}

\chapter{Maximum Likelihood Estimator Bayesian Inference DNA Origami  Nanorod Barcode Detection}

\section{Introduction}
\newthought{The development of next generation microarray and on-chip technologies} will depend in part upon advancements in fluorescent reporter molecules and improvements in their detection.

Currently accepted microarray techniques  use at most two spectrally distinct fluorophores to identify their targets.  Recently, however, there has been an explosion in fluorescent reporter approaches that enables an observer to uniquely identify one out of many hundreds of distinct fluorescent encoded reporters. Researchers have explored both combining spectrally distinct fluorophores in close proximity to create gradations of colors[cite a bunch of stuff], and spatially separating fluorophores to create geometric optical barcodes [cite a bunch of stuff]. In particular, fluorescently encoded DNA based nanorods [cite the DNA related ones] provide a promising avenue to DNA based micro-array techniques. Instead of identifying DNA microarray targets largely by location, this raises the distinct possibility of also unambiguously identifying targets by fluorescent encoding. 

Programmatically identifying images of these fluorescently encoded barcodes, however, presents unique computational challenges that have not yet been explored in the literature.  Here we describe a mathematical formalism that allows us to use computer vision to optimally detect DNA origami-based nanorod barcodes. We take a bayesian inference approach, and demonstrate that our implementation allows for >blah \% correct barcode identification under real-world situations. 

\section{System and Methods}

\subsection{DNA origami nanorod barcodes}
We chose to image DNA origami nanorod barcodes [cite chenxiang]. These nanorods consist of mechanically rigid six-helix bundles of DNA with radius 5 nm and length XY \textmu m decorated with  up to two spectrally distinct fluorophores at three distinct locations along the rod, as illustrated in Fig.~\ref{nanoAnalysis}. The three fluorescing locations are unevenly spaced, with a large gap of \textasciitilde 450 \textmu m and a small gap of \textasciitilde 270 \textmu m  between the fluorophores on each rod, giving the barcodes a visible anisotropy. When using combinations of red, green and blue fluorophores, (Cy5, Cy3 and Alexa Fluor 488, respectively) this allows for a dictionary of six fluorescing symbols at each of the three barcode locations: \{Red, Green, Blue, RedGreen, RedBlue, GreenBlue\}, for a total of $6^{3}=216$  unambiguous species of barcode.

We chose to work with this particular form of fluorescently encoded barcodes as opposed to others because this form offer the largest published number of distinct barcode species to date, has the advantage of being massively self-assembled in parallel, and creates barcodes of suitably small  size so as to be useful for future microarray applications. 

The barcodes are, in fact, so small that the distance between fluorescing sites is often smaller than a wavelength of light. As a result, when the barcodes are imaged on a flat surface, the distinct flourescent sites appear to blend into one another. This becomes one of the primary challenges facing any computer vision barcode identification software, namely to  decode the barcode even when the individual difraction-limited fluorescent spots overlap. 

\subsection{Imaging}
Barcodes were imaged on a glass cover slide on a BLAH BLAH microscope,  under total internal reflection fluorescence (TIRF). 
The red, green and blue channel images of the barcodes were taken on a glass coverslip, with purple (XXXnm), green (XXXnm) or blue (XXXnm) laser light at YYY mW, ZZZ mW and XXXX mW incident power, respectively. A BLAH BLAH EMCCD camera was used with an exposure time of BLAH ms.
 
\subsection{Task at Hand}
To be useful for microarray or other diagnostic applications, it is important for any computer vision software to be able to automatically detect and decode large quantities of barcodes robustly and accurately with little or no user input. 
Here we restrict ourselves to immobilized barcodes laying flat on a glass slide, but we demand that our software solution tolerate likely real-world complexities including the presence of inhomogeneous spatial illumination, background fluorescence and minor defects in barcode folding.  
In the following sections we develop an optimal mathematical framework and software implementation for identifying the location and orientation of the barcode and then decoding it.


\section{Theory and Algorithm}
To automatically detect and decode a barcode from its three-channel image, the software must systematically scan through the image, detect the location of each barcode and decide which of the 216 reference barcode species best fits the observed barcode. Assigning the best fitting reference, or model, barcode is performed by Bayesian multiple hypothesis testing. This is, in general, computational intensive for two-dimensional datasets, so we first turn for guidance to a one-dimensional problem.


\subsection{One dimension, single channel}
In the one dimensional problem we assume there are $K$ possible one-dimensional reference signals in a system with zero-mean additive Gaussian noise $n$, such that for any reference $m$, the observed signal $\mathbf{u}$ is
\begin{equation}
\mathbf{u}=\mathbf{m} + \mathbf{n},
\end{equation}
vector notation. Given a noisy observation $\mathbf{u}$, we seek the most likely corresponding reference or model signal. 

%%%
% Suggestions for Notation
% Added Monday: since we'll talk about 1D case first, let's use 'u' for 1D. 'v' is then natural for 2D data that follows.
% j=1...J, where J=3. Color index (red green blue).
% \mathbf{m}_k = kth model, K = total # barcodes
% v(x,y) = raw observed voltage at pixel x,y. Probably won't mention the x,y coordinates for most of what we do
% c = camera offset constant
% n(x,y) = noise
% so v = a*\mathbf{m}_k + n + c where a is ampl
% u(x) = 1D case, which is what reduced observed data (offset removed, scale flattened, and projected) becomes
% std probability notation p(H|D) = prob. of H given D
% \mathbf{R}_n = noise covariance matrix
% \sigma_j^2 = noise variance of jth color image
% <.> = expectation (or use overbar)


The probablity that the $k$th reference signal $\mathbf{m}_k$ is present when the data vector $\mathbf{u}$ is observed is given by Bayes' theorem,
\begin{equation}\label{eq:Bayes}
p(\mathbf{m}_k|\mathbf{u}) = \frac{p(\mathbf{u}|\mathbf{m}_k)p(\mathbf{m}_k)} {p(\mathbf{u})},
\end{equation}
where $p(\mathbf{m}_k|\mathbf{u})$ is the inverse probability, $p(\mathbf{u}|\mathbf{m}_k)$ is the forward probability or likelihood of seeing data $\mathbf{u}$ given the presence of model $\mathbf{m}_k$, $p(\mathbf{m}_k)$ is the prior probability that model $\mathbf{m}_k$ is present, and $p(\mathbf{u})$ is a normalization constant.

We seek to compute the probability for each possible reference $\mathbf{m}_k$, $k=1,2,3 \ldots K$, and select the largest, which is the one most likely to fit the observed data. This is termed the maximum likelihood solution.

While testing a particular observed signal $\mathbf{u}$ against all models, the denominator is constant and independent of $k$. Maximizing $p(\mathbf{m}_k|\mathbf{u})$ is therefore equivalent to finding the model $k$ that maximizes the product  $p(\mathbf{u}|\mathbf{m}_k)p(\mathbf{m}_k)$.
In the present case where all barcodes are equally probable so that
$p(\mathbf{m}_k)=1/K,$ 
the search simplifies to finding the maximum likelihood 
\begin{equation}
L_k = p(\mathbf{u}|\mathbf{m}_k).
\end{equation}



The probability $p(\mathbf{u}|\mathbf{m}_k)$ of observing $\mathbf{u}$ given the reference $\mathbf{m}_k$ is simply the probability that the difference $\mathbf{u}-\mathbf{m}_k$ between the signal and the reference is generated by noise. This is given by the multivariate probability density function for the random Gaussian variable $(\mathbf{u}-\mathbf{m}_k)$, 
\begin{equation}\label{eq:Main}
L_k = p(\mathbf{u}|\mathbf{m}_k) = \frac{1}{  \sqrt{ (2\pi)^N \det || \mathbf{R}_n||} } \exp\left[ -\frac{1}{2}  (\mathbf{u}-\mathbf{m}_k)^T \mathbf{R}_n^{-1} (\mathbf{u}-\mathbf{m}_k) \right]
\end{equation}
where $N$ is the length of vector $\mathbf{u}$, $\mathbf{R}_n$ is the noise covariance matrix, det||.|| is the matrix determinant, and $T$ denotes the transpose operation [REFERENCE].
 
For the case of identical independently distributed (IID) Gaussian noise, 
\begin{equation}
\mathbf{R}_n=\sigma^2 \mathbf{I}
\end{equation}
where $\mathbf{I}$ is the identity matrix and $\sigma^2$ is the variance of the noise. The probability thus reduces further to
\begin{equation}\label{eq:iidEnergy}
L_k = p(\mathbf{u}|\mathbf{m}_k) = \frac{1}{  \sigma^N \sqrt{ (2\pi)^N}   } \exp\left[ -\frac{(\mathbf{u}-\mathbf{m}_k)^T(\mathbf{u}-\mathbf{m}_k)} {2 N \sigma^2 } \right].
\end{equation}

The exponent is simply the energy contained in the sequence $\mathbf{u}-\mathbf{m}_k$ divided by the
energy of a sequence of sequence of noise of length $N$ and variance $\sigma^2$. We recognize parallels to the Maxwell-Boltzmann distribution of statistical mechanics [CITE REIF].  

As mentioned, we find the $\mathbf{m}_k$ that produces the maximum likelihood in equation \ref{eq:iidEnergy},
\begin{equation}
\max_k   \left\{ p(\mathbf{u}|\mathbf{m}_k) \right\} =  \max_k  \left\{ \frac{1}{   \sigma^N\sqrt{ (2\pi)^N}  } \exp\left[ -\frac{(\mathbf{u}-\mathbf{m}_k)^T(\mathbf{u}-\mathbf{m}_k)} {2 N \sigma^2 } \right] \right\}. 
\end{equation}
Since $\sigma$ and $N$ are independent of $k$ and the exponential is a monotonically increasing function of its argument, maximizing the likelihood across $k$ is equivalent to minimizing the energy of the difference between the observation and the reference across $k$ 

\begin{equation}
\max_k   \left\{ p(\mathbf{m}_k|\mathbf{u}) \right\} \sim \min_k  \left\{ (\mathbf{u}-\mathbf{m}_k)^T(\mathbf{u}-\mathbf{m}_k) \right\}. 
\end{equation}
It is noteworthy that the Bayesian hypothesis test is equivalent in this case to finding the $k$ that minimizes the mean squared error between observation and reference. This is clear by rewriting this expression explicitly in terms of a sum,
\begin{equation}
\max_k   \left\{ p(\mathbf{m}_k|\mathbf{u}) \right\} =  \min_k  \left\{ \sum_{i=1}^N  (u_i-m_{k,i})^2   \right\}. 
\end{equation}

\subsection{One dimension, multiple channels}\label{sec:simpleModel}
We now consider a system where each reference $\mathbf{m}_k$ consists of three one-dimensional vectors $\mathbf{m}_{k1}$, $\mathbf{m}_{k2}$ and $\mathbf{m}_{k3}$ of length $N$. Each will correspond to the portion of the reference contained in a different channel, but there are still $K$ references. Analogously, the signal $\mathbf{u}$ also consists of three one-dimensional observations $\mathbf{u}_1$, $\mathbf{u}_2$ and $\mathbf{u}_3$, each in its own channel, and each channel has zero-mean additive IID Gaussian noise with variances $\sigma_1^2$, $\sigma_2^2$ and $\sigma_3^2$, respectively. As we will see later, these channels can be thought of as the red, green and blue channels in a one-dimensional composite color image. 

Because the three channels are independent, the likelihood that signal $\mathbf{u}$ is observed when $\mathbf{m}_k$ is present simply factors into the product of the individual likelihoods, that is, the likelihood that $\mathbf{u}_1$ is observed when $\mathbf{m}_{k1}$ is present times the likelihood that $\mathbf{u}_2$ is observed when $\mathbf{m}_{k2}$ is present times the likelihood that $\mathbf{u}_3$ is observed when $\mathbf{m}_{k3}$ is present [CITE ELEMENTARY PROBABILITY],
\begin{equation}
p(\mathbf{u}|\mathbf{m}_k) = p(\mathbf{u}_1|\mathbf{m}_{k1})p(\mathbf{u}_2|\mathbf{m}_{k2})p(\mathbf{u}_3|\mathbf{m}_{k3}).
\end{equation}

Substituting Eq.~\ref{eq:iidEnergy} gives
\begin{multline}
\Lambda_k=p(\mathbf{u}|\mathbf{m}_k) =\frac{1}{ (\sigma_1\sigma_2\sigma_3)^N  \sqrt{ (2\pi)^{3N}}  }  \exp\Bigg[ -\frac{(\mathbf{u}-\mathbf{m}_{k1})^T(\mathbf{u}-\mathbf{m}_{k1})} {2 N \sigma_1^2 }   - \\ \frac{(\mathbf{u}-\mathbf{m}_{k2})^T(\mathbf{u}-\mathbf{m}_{k2})} {2 N \sigma_2^2 } -\frac{(\mathbf{u}-\mathbf{m}_{k3})^T(\mathbf{u}-\mathbf{m}_{k3})} {2 N \sigma_3^2 }    \Bigg].
\end{multline}

As before, we can factor out and ignore terms that have no $k$ dependence. Thus the maximum likelihood model $k$ correspond to finding $k$ that minimizes the quantity below:
\begin{multline}
\max_k   \big\{ p(\mathbf{m}_k|\mathbf{u}) \big\} =  \min_k  \Bigg\{  \frac{(u_1-\mathbf{m}_{k1})^T(u_1-\mathbf{m}_{k1})}{\sigma_1^2} +\\  
\frac{(u_2-\mathbf{m}_{k2})^T(u_2-\mathbf{m}_{k2})}{\sigma_2^2} + \frac{(u_3-\mathbf{m}_{k3})^T(u_3-\mathbf{m}_{k3})}{\sigma_3^2} \Bigg\}. 
\end{multline}




\subsection{2D Multi-Channel Image}
We would like to apply the simple model described above to the problem of identifying the barcodes in our two-dimensional images. Before we can do so, we must perform image processing on our two dimensional images to bring them in line with the assumptions of our one-dimensional model.

%Added in an explanation of noise in our image
We assume that the contributions to noise in our barcode images are Gaussian, zero-mean and additive. We will show this experimentally later. It is clear from inspection, however, that the background of the barcode images do not have zero mean and also have a slowly varying spatial inhomogeneity. To remove this slowly-varying non-zero-mean background we must fully account for the various contributions to the signal recorded at our detector



%neither of which are  taken into account in the model. Additionally, the images contain an unknown number of %barcodes at  unknown locations, while the model assumes exactly one barcode at a known location. The simple %model also assumes that the reference and observation waveforms have the same known height, and of course the %model is designed for one dimension. 

%Here we address each one of these issues.



%Moreover, the model assumes than in an observation  $\mathbf{u}$ there is exactly one reference at a known location, but our images contain an unknown number of barcodes at unknown locations. 


%	\begin{enumerate} %Why is this datest different from all other datasets?
%	\item The simple model assumes that the noise is additive, zero-mean, and IID. The images exhibit a slowly varying offset, and therefore exhibit noise that is neither zero-mean nor IID. \label{item:noise}
%	\item The simple model assumes that the observation $\mathbf{u}$ contains exactly one reference at a known location, but our images contain an unknown number of barcodes at unknown locations. 
%	\item The simple model assumes that the reference $\mathbf{m_k}$ and observation $\mathbf{u}$ waveforms have the same known height, but in our images the height is \textit{a priori} unknown and may vary within an image.  
%	\item The simple model assumes a one-dimensional image, but our images are two dimensional.
%	\end{enumerate} 
%We will address the discrepancies listed above by employing image processing techniques to transform our raw images into a dataset that can be analyzed using the simple one-dimensional multi-channel model described in Section \ref{sec:simpleModel}. 
. 

The voltage $V(\mathbf{r})$ at a pixel $\mathbf{r}$ of our detector is the sum of a term that is proportional to the number of incident photons, plus a DC offset $V_0(\mathbf{r})$ that can slowly vary from pixel to pixel, plus thermal noise $n_{\text{therm}}$ which we assume is Gaussian and zero-mean,
\begin{equation}
V(\mathbf{r})=V_0(\mathbf{r})+c \cdot \text{Photons}(\mathbf{r}) +n_{\text{therm}}.
\end{equation}
Recall that in our system, laser light at one wavelength is incident on the sample and stimulates the emission from a fluorophore of photons at another wavelength that is capable of reaching the detector. Photons that reach the detector must have been re-emitted from fluorophores located either in the barcodes themselves $f$ or in the background media $b$, which consists of a glass slide and buffer.  In both cases, we model the number of photons that are re-emitted as proportional to the number of incident photons plus some noise term, which we assume is Gaussian and zero-mean, 
\begin{eqnarray}
f(\mathbf{r})&=&\gamma_{\text{ex}}(\mathbf{r}) ( q_f(\mathbf{r}) + n_f )\\
b(\mathbf{r})&=&\gamma_{\text{ex}}(\mathbf{r}) ( q_b + n_b ).
\end{eqnarray}
Where  $\gamma_{\text{ex}}(\mathbf{r})$ is the slowly varying position-dependent intensity of the excitation laser,  $q_f(\mathbf{r})$ describes the position-dependent fluorescent efficiency of the barcodes independent of illumination, and $q_b$ is the background fluorescent efficiency of the media which we assume is independent of position and illumination. 

The contributions of these terms can be evaluated by recording auxiliary images. The offset and thermal noise are present in a dark image taken when the laser is off, for example, while the background noise and spatially varying illumination become visible in an image taken with the laser on but with empty media present. The final image, of course, adds DNA barcodes to the media. The voltages recorded in these cases are
\begin{eqnarray}
V_{\text{empty}}(\mathbf{r})&=&V_0(\mathbf{r})+n_{\text{therm}}\\
V_{\text{back}}(\mathbf{r})&=&V_0(\mathbf{r})+c \cdot  b(\mathbf{r})  +n_{\text{therm}}\\
V_{\text{fluor}}(\mathbf{r})&=&V_0(\mathbf{r})+c \cdot \big( f(\mathbf{r}) + b(\mathbf{r})\big)  +n_{\text{therm}}
\end{eqnarray}
See Fig BLAH BLAH. 

We smooth the dark and background images and subtract and divide them to remove the DC offset and compensate for the spatially varying illumination, respectively,
\begin{equation}
V_{\text{processed}}(\mathbf{r})= \frac{ V_{\text{fluor}}(\mathbf{r}) - \langle V_{\text{back}}(\mathbf{r}) \rangle }{ \langle V_{\text{back}}(\mathbf{r}) \rangle - \langle V_{\text{empty}}(\mathbf{r}) \rangle}
\end{equation}
where $\langle~\rangle$ denotes the expectation value. Substituting Eq. XXX gives
\begin{equation}
V_{\text{processed}}(\mathbf{r})= \frac{ c \cdot \big( f(\mathbf{r})  +b(\mathbf{r}) -\langle b(\mathbf{r}) \rangle \big)+ n_{\text{therm}} - \langle n_{\text{therm}}  \rangle }{   c \cdot \langle b(\mathbf{r}) \rangle }
\end{equation}
Note that we assume $\langle V_0(\mathbf{r}) \rangle = V_0(\mathbf{r})$ and $\langle \gamma_{\text{ex}}(\mathbf{r}) \rangle  = \gamma_{\text{ex}}(\mathbf{r})$ because both are modeled as deterministic processes. Substituting further, and recalling that the mean of the noise terms are zero,
\begin{equation}
V_{\text{processed}}(\mathbf{r})= \frac{ c \cdot \gamma_{\text{ex}}(\mathbf{r}) \big(  q_f(\mathbf{r}) + n_{\text{fluor}}       +   n_{\text{back}}   \big) + n_{\text{therm}}  }{     c \gamma_{\text{ex}}(\mathbf{r})  q_b }
\end{equation}
\begin{equation}
V_{\text{processed}}(\mathbf{r})= \frac{ q_f(\mathbf{r}) }{ q_b} + \frac{n_{\text{fluor}}   +   n_{\text{back}} } {q_b}  + \frac{ n_{\text{therm}} }{   c \gamma_{\text{ex}}(\mathbf{r}) q_b} 
\end{equation}
We observe that the thermal noise $n_{\text{therm}}$ is much much smaller compared to fluorescent background (easy to measure, just the fluctuations of the blank image ~100 vs the background ~ 10,000).

Now we can measure the sum of  $n_{\text{fluor}}$ and $n_{\text{back}}$ and show that they are  zero mean, Gaussian and IID. 


Also now  the height of the barcodes are the same, they simply need to be measured, but the qback has no spatial variation, and qfluor is the same for all barcodes. So now we are in good shape!




\subsection{Garbage	} 

We also assume that the nature of fluorescence itself is noisy, and since we assume the integration time of our detector is long, and thus each pixel will contain many many photons, we assume that the by the central limit theorem the noise from fluorescence should be Gaussian.






Before we can use the formalisms described above, we must first ensure that our data matches the assumptions: gaussian, IID, mean zero, one-dimensional. 

Without processing, the noise in the two-dimension, three-channel nanorod barcode images are non-gaussian, non-identicially distributed, they lack a zero offset and they are two dimensional.



Now we seek to reduce our three-channel two-dimensional barcode images into three-channel one-dimensional data. 



%bold non-ital uppercase for matrices
%bold non-ital lowercase for vectors


%Walk through



ASSUMPTION: The camera is just a photon counter. The noise we see comes overwhelmingly from "background fluorescence". We assume it is additive, thus we assume that our signal is merely superposed on top of the mean background. 

This implies that there is a single true peak height that is valid for all peaks. To test this assumption, I should background subtract the local mean from the barcodes and measure the height single isolated peaks. The height of locally background subtracted single isolated peaks should be flat and not correlate with location in the image.

This would mean that when identifying our barcode we don't have to scale our reference, we can use a single reference for all barcodes regardless of the location.


\section{Manuscript Information}
\subsection{Submitted for Publication As}
A version of this chapter has been submitted for publication in the journal \textit{Bioinformatics}.
% in \citep{leifer_optogenetic_2011}:
%\bibentry{leifer_optogenetic_2011}

\subsection{The Author's Contribution}
Andrew M.~Leifer wrote all of the software, generated all figures, developed portions of the mathematical framework, and wrote the majority of the manuscript. Mark C.~Leifer developed portions of the mathematical framework and wrote selected passages of the manuscript. Chenxiang Lin created the DNA origami barcodes and conducted all microscopy work. 
 