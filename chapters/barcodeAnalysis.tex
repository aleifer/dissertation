% mark's edit!!!!

%Andy's edit!! Even Better!
%!TEX root = /Users/andy/Documents/Academics/Dissertation/thesis.tex
\begin{savequote}[75mm] 
This is some random quote to start off the chapter.
\qauthor{Firstname lastname} 
\end{savequote}

\chapter{Maximum Likelihood Estimator Bayesian Inference DNA Origami  Nanorod Barcode Detection}

\section{Introduction}
\newthought{The development of next generation microarray and on-chip technologies} will depend in part upon advancements in fluorescent reporter molecules and improvements in their detection.

Currently accepted microarray techniques  use at most two spectrally distinct fluorophores to identify their targets.  Recently, however, there has been an explosion in fluorescent reporter approaches that enables an observer to uniquely identify one out of many hundreds of distinct fluorescent encoded reporters. Researchers have explored both combining spectrally distinct fluorophores in close proximity to create gradations of colors[cite a bunch of stuff], and spatially separating fluorophores to create geometric optical barcodes [cite a bunch of stuff]. In particular, fluorescently encoded DNA based nanorods [cite the DNA related ones] provide a promising avenue to DNA based micro-array techniques. Instead of identifying DNA microarray targets largely by location, this raises the distinct possibility of also unambiguously identifying targets by fluorescent encoding. 

Programmatically identifying images of these fluorescently encoded barcodes, however, presents unique computational challenges that have not yet been explored in the literature.  Here we describe a mathematical formalism that allows us to use computer vision to optimally detect DNA origami-based nanorod barcodes. We take a bayesian inference approach, and demonstrate that our implementation allows for >blah \% correct barcode identification under real-world situations. 

\section{System and Methods}

\subsection{DNA origami nanorod barcodes}
We chose to image DNA origami nanorod barcodes [cite chenxiang]. These nanorods consist of mechanically rigid six-helix bundles of DNA with radius 5 nm and length XY \textmu m decorated with  up to two spectrally distinct fluorophores at three distinct locations along the rod, as illustrated in Fig.~\ref{nanoAnalysis}. The three fluorescing locations are unevenly spaced, such that there is a larger gap of \textasciitilde 450 \textmu m and a smaller gap of \textasciitilde 270 \textmu m  between the fluorophores on each rod, giving the barcodes a visible anisotropy. When using combinations of red, green and blue fluorophores, (Cy5, Cy3 and Alexa Fluor 488, respectively) this allows for a dictionary of six fluorescing symbols at each of the three barcode locations: \{Red, Green, Blue, RedGreen, RedBlue, GreenBlue\}, for a total of $2^{6}=216$  unambiguous species of barcode.

We chose to work with this particular form of fluorescently encoded barcodes as opposed to others because this form offer the largest published number of distinct barcode species to date, has the advantage of being massively self-assembled in parallel, and creates barcodes of suitably small  size so as to be useful for future microarray applications. 

The barcodes are, in fact, so small that the distance between fluorescing sites is often smaller than a wavelength of light. As a result, when the barcodes are imaged on a flat surface, the distinct flourescent sites appear to blend into one another. This becomes one of the primary challenges facing any computer vision barcode identification software, namely to  decode the barcode even when the individual difraction-limited fluorescent spots overlap. 

\subsection{Imaging}
Barcodes were imaged on a glass cover slide on a BLAH BLAH microscope,  under total internal reflection fluorescence (TIRF). 
The red, green and blue channel images of the barcodes were taken on a glass coverslip, with purple (XXXnm), green (XXXnm) or blue (XXXnm) laser light at YYY mW, ZZZ mW and XXXX mW incident power, respectively. A BLAH BLAH EMCCD camera was used with an exposure time of BLAH ms.
 
\subsection{Task at Hand}
To be useful for microarray or other diagnostic applications, it is important for any computer vision software to be able to automatically detect and decode large quantities of barcodes robustly and accurately with little or no user input. 
Here we restrict ourselves to immobilized barcodes laying flat on a glass slide, but we demand that our software solution tolerate  likely real-world complexities including the presence of inhomogeneous spatial illumination, background fluorescence and minor defects in barcode folding.  
In the following sections we develop an optimal mathematical framework and software implementation for identifying the location and orientation of the barcode and then decoding it.


\section{Theory and Algorithm}
To automatically detect and decode a barcode from its three-channel image, the software must systematically scan through the image, detect the location of each barcode and decide which of the 216 reference barcode species best fits the observed barcode. Assigning the best fitting reference, or model, barcode is performed by Bayesian multiple hypothesis testing. This is generally computational intensive for two-dimensional datasets, so we turn for guidance to a simpler problem: detecting the presence of a known one-dimensional reference signal $m_k% in additive zero-mean Gaussian noise n. In vector notation, the data sequence being tested u is 
\begin{equation}
u=m_k + n.
\end{equation}

%%%
% Suggestions for Notation
% Added Monday: since we'll talk about 1D case first, let's use 'u' for 1D. 'v' is then natural for 2D data that follows.
% j=1...J, where J=3. Color index (red green blue).
% m_k = kth model, K = total # barcodes
% v(x,y) = raw observed voltage at pixel x,y. Probably won't mention the x,y coordinates for most of what we do
% c = camera offset constant
% n(x,y) = noise
% so v = a*m_k + n + c where a is ampl
% u(x) = 1D case, which is what reduced observed data (offset removed, scale flattened, and projected) becomes
% std probability notation p(H|D) = prob. of H given D
% R_n = noise covariance matrix
% \sigma_j^2 = noise variance of jth color image
% <.> = expectation (or use overbar)





Bayesian testing of multiple hypotheses consists of evaluating the inverse probability for all models, and declaring the model with the largest probability of correspondence to the data u as the best guess of the signal identity. Bayes' theorem gives the inverse probability that $m_k$ is present in the data %u%
\begin{equation}
p(m_k|u) = \frac{p(u|m_k)p(m_k)}{p(u)},
\end{equation}
where $p(u|m_k)$ is the forward probability or likelihood of seeing data u given the presence of model $m_k$, $p(m_k) is the prior probability that model $m_k$ is present, and $p(u)$ is a normalization constant.
% That's as far as I got...

While testing a given image against all models, the denominator is constant and independent of $k$. Maximizing $p(m_k|u)$ is therefore equivalent to finding the model k that maximizes the product
\begin{equation}
\Lambda_k = p(u|m_k)p(m_k).
\end{equation}
In the present case where all barcodes are equally probable so that
$p(m_k)=1/K,$ 
the search simplifies to finding the maximum likelihood 
\begin{equation}
\Lambda_k = p(u|m_k).
\end{equation}



The quantity $u - m_k$ will be noise if u contains the sequence m_k, or will be large and deterministic if u instead contains a different sequence m_i. The probability $p(m_k|u)$ that the $k$th reference $m_k$ is present given the observed signal $u$ is proportional to the probability that the difference between the signal and the reference $u-m_k$ could be entirely due to noise,



\begin{equation}
p(u|m_k)\sim p(u|m_k) \sim \frac{1}{  \sqrt{ (2\pi)^K \det || R_n||} } \exp\left\{ -\frac{1}{2}  (u-m_k)^T R_n^{-1} (u-m_k) \right\}
\end{equation}

where $R_n$ is the noise covariance matrix. 

\begin{equation}
p(u|m_k)\sim p(u|m_k) \sim \frac{1}{  \sqrt{ (2\pi)^K \det || R_n||} } \exp\left\{ -\frac{1}{2}  (u-m_k)^T R_n^{-1} (u-m_k) \right\}
\end{equation}

Where $R_{n}$ is the covariance matrix of the noise.

%bold non-ital uppercase for matrices
%bold non-ital lowercase for vectors


%Walk through

Aggregating mean-subtracted ROI's from across the image and finding the variance.

Now we go through the barcodes and try to identify them.

Given a barcode, we find the local background and scale the reference accordingly. 

ASSUMPTION: The camera is just a photon counter. The noise we see comes overwhelmingly from "background fluorescence". We assume it is additive, thus we assume that our signal is merely superposed on top of the mean background. 

This implies that there is a single true peak height that is valid for all peaks. To test this assumption, I should background subtract the local mean from the barcodes and measure the height single isolated peaks. The height of locally background subtracted single isolated peaks should be flat and not correlate with location in the image.

This would mean that when identifying our barcode we don't have to scale our reference, we can use a single reference for all barcodes regardless of the location.


\section{Manuscript Information}
\subsection{Submitted for Publication As}
A version of this chapter has been submitted for publication in the journal \textit{Bioinformatics}.
% in \citep{leifer_optogenetic_2011}:
%\bibentry{leifer_optogenetic_2011}

\subsection{The Author's Contribution}
Andrew M.~Leifer wrote all of the software, generated all figures, developed portions of the mathematical framework, and wrote the majority of the manuscript. Mark C.~Leifer developed portions of the mathematical framework and wrote selected passages of the manuscript. Chenxiang Lin created the DNA origami barcodes and conducted all microscopy work. 
 