%!TEX root = /Users/andy/Documents/Academics/Dissertation/thesis.tex
\begin{savequote}[75mm] 
This is some random quote to start off the chapter.
\qauthor{Firstname lastname} 
\end{savequote}

\chapter{Maximum Likelihood Estimator Bayesian Inference DNA Origami  Nanorod Barcode Detection}

\section{Introduction}
\newthought{The development of next generation microarray and on-chip technologies} will depend in part upon advancements in fluorescent reporter molecules and improvements in their detection.

Currently accepted microarray techniques  use at most two spectrally distinct fluorophores to identify their targets.  Recently, however, there has been an explosion in fluorescent reporter approaches that enables an observer to uniquely identify one out of many hundreds of distinct fluorescent encoded reporters. Researchers have explored both combining spectrally distinct fluorophores in close proximity to create gradations of colors[cite a bunch of stuff], and spatially separating fluorophores to create geometric optical barcodes [cite a bunch of stuff]. In particular, fluorescently encoded DNA based nanorods [cite the DNA related ones] provide a promising avenue to DNA based micro-array techniques. Instead of identifying DNA microarray targets largely by location, this raises the distinct possibility of also unambiguously identifying targets by fluorescent encoding. 

Programmatically identifying images of these fluorescently encoded barcodes, however, presents unique computational challenges that have not yet been explored in the literature.  Here we describe a mathematical formalism that allows us to use computer vision to optimally detect DNA origami-based nanorod barcodes. We take a bayesian inference approach, and demonstrate that our implementation allows for >blah \% correct barcode identification under real-world situations. 

\section{System and Methods}

\subsection{DNA origami nanorod barcodes}
We chose to image DNA origami nanorod barcodes [cite chenxiang]. These nanorods consist of mechanically rigid six-helix bundles of DNA with radius 5 nm and length XY \textmu m decorated with  up to two spectrally distinct fluorophores at three distinct locations along the rod, as illustrated in Fig.~\ref{nanoAnalysis}. The three fluorescing locations are unevenly spaced, such that there is a larger gap of \textasciitilde 450 \textmu m and a smaller gap of \textasciitilde 270 \textmu m  between the fluorophores on each rod, giving the barcodes a visible anisotropy. When using combinations of red, green and blue fluorophores, (Cy5, Cy3 and Alexa Fluor 488, respectively) this allows for a dictionary of six fluorescing symbols at each of the three barcode locations: \{Red, Green, Blue, RedGreen, RedBlue, GreenBlue\}, for a total of $6^{3}=216$  unambiguous species of barcode.

We chose to work with this particular form of fluorescently encoded barcodes as opposed to others because this form offer the largest published number of distinct barcode species to date, has the advantage of being massively self-assembled in parallel, and creates barcodes of suitably small  size so as to be useful for future microarray applications. 

The barcodes are, in fact, so small that the distance between fluorescing sites is often smaller than a wavelength of light. As a result, when the barcodes are imaged on a flat surface, the distinct flourescent sites appear to blend into one another. This becomes one of the primary challenges facing any computer vision barcode identification software, namely to  decode the barcode even when the individual difraction-limited fluorescent spots overlap. 

\subsection{Imaging}
Barcodes were imaged on a glass cover slide on a BLAH BLAH microscope,  under total internal reflection fluorescence (TIRF). 
The red, green and blue channel images of the barcodes were taken on a glass coverslip, with purple (XXXnm), green (XXXnm) or blue (XXXnm) laser light at YYY mW, ZZZ mW and XXXX mW incident power, respectively. A BLAH BLAH EMCCD camera was used with an exposure time of BLAH ms.
 
\subsection{Task at Hand}
To be useful for microarray or other diagnostic applications, it is important for any computer vision software to be able to automatically detect and decode large quantities of barcodes robustly and accurately with little or no user input. 
Here we restrict ourselves to immobilized barcodes laying flat on a glass slide, but we demand that our software solution tolerate  likely real-world complexities including the presence of inhomogeneous spatial illumination, background fluorescence and minor defects in barcode folding.  
In the following sections we develop an optimal mathematical framework and software implementation for identifying the location and orientation of the barcode and then decoding it.


\section{Theory and Algorithm}
To automatically detect and decode a barcode from its three-channel image, the software must systematically scan through the image, detect the location of each barcode and decide which of the 216 reference barcode species best fits the observed barcode. Assigning the best fitting reference, or model, barcode is performed by Bayesian multiple hypothesis testing. This is, in general, computational intensive for two-dimensional datasets, so we first turn for guidance to a one-dimensional problem.


\subsection{One dimension, single-channel}
In the one dimensional problem we assume we have $K$ possible one-dimensional reference signals in a system with zero-mean additive gaussian noise $n$, such that for any reference $m$, the observed signal $u$ is, in vector notation,
\begin{equation}
u=m + n.
\end{equation}
Given a noisy observation $u$, we seek the most likely corresponding reference. 

%%%
% Suggestions for Notation
% Added Monday: since we'll talk about 1D case first, let's use 'u' for 1D. 'v' is then natural for 2D data that follows.
% j=1...J, where J=3. Color index (red green blue).
% m_k = kth model, K = total # barcodes
% v(x,y) = raw observed voltage at pixel x,y. Probably won't mention the x,y coordinates for most of what we do
% c = camera offset constant
% n(x,y) = noise
% so v = a*m_k + n + c where a is ampl
% u(x) = 1D case, which is what reduced observed data (offset removed, scale flattened, and projected) becomes
% std probability notation p(H|D) = prob. of H given D
% R_n = noise covariance matrix
% \sigma_j^2 = noise variance of jth color image
% <.> = expectation (or use overbar)


The probablity that the observed signal $u$ is composed of the $k$th reference signal $m_k$ is given by Baye's theorem,
\begin{equation}\label{eq:Bayes}
p(m_k|u) = \frac{p(u|m_k)p(m_k)} {p(u)}.
\end{equation}
where $p(m_k|u)$ is the inverse probability, $p(u|m_k)$ is the forward probability or likelihood of seeing data $u$ given the presence of model $m_k$, $p(m_k)$ is the prior probability that model $m_k$ is present, and $p(u)$ is a normalization constant.

We seek to compare the relative  probability for each possible reference, $m_k$ for $k=1,2,3 \ldots K$ and select the most likely, $\Lambda_k$.  

While testing a given observed sginal $u$ against all models, the denominator is constant and independent of $k$. Maximizing $p(m_k|u)$ is therefore equivalent to find the model $k$ that maximizes the product
\begin{equation}
\Lambda_k = p(u|m_k)p(m_k).
\end{equation}
In the present case where all barcodes are equally probable so that
$p(m_k)=1/K,$ 
the search simplifies to finding the maximum likelihood 
\begin{equation}
\Lambda_k = p(u|m_k).
\end{equation}



The probability $p(u|m_k)$ of observing $u$ given the reference $m_k$  is simply the probability that the difference between the signal and the reference $u-m_k$ could be entirely generated by noise.
\begin{equation}\label{eq:Main}
p(m_k|u)\sim p(u|m_k) = \frac{1}{  \sqrt{ (2\pi)^N \det || R_n||} } \exp\left\{ -\frac{1}{2}  (u-m_k)^T R_n^{-1} (u-m_k) \right\}
\end{equation}
where $N$ is the length of vector $u$ and $R_n$ is the noise covariance matrix. 

For the case of identical independantly distributed (IID) gaussian noise, 
\begin{equation}
R_n=\sigma^2 I
\end{equation}
where $I$ is the identity matrix and $\sigma^2$ is the variance of the noise. The probability thus reduces further to
\begin{equation}\label{eq:iidEnergy}
p(m_k|u)\sim p(u|m_k) = \frac{1}{  \sqrt{ (2\pi)^N} \sigma^N  } \exp\left\{ -\frac{(u-m_k)^T(u-m_k)} {2 N \sigma^2 } \right\}.
\end{equation}

The exponent is simply the energy contained in the sequence $u-m_k$ divided by the
theoretical energy that a sequence of length $N$ would have were it pure noise with variance $\sigma^2$. We recognize parallels to the Maxwell-Boltzmann distribution of statistical
mechnanics [CITE REIF].  


If we maximize the previous equation over $k$ we can attain the most likely reference, $\Lambda_k$,


\begin{equation}
\max_k   \big\{ p(m_k|u) \big\} =  \max_k  \left\{ \frac{1}{  \sqrt{ (2\pi)^N} \sigma^N  } \exp\left\{ -\frac{(u-m_k)^T(u-m_k)} {2 N \sigma^2 } \right\} \right\}. 
\end{equation}

We note that $\sigma$ and $N$ are indpenednet of $k$, and that the exponential is a monotonically increasing function, thus we must only minimize across $k$ the energy of the difference between the observation and the reference,

\begin{equation}
\max_k   \big\{ p(m_k|u) \big\} =  \min_k  \left\{ (u-m_k)^T(u-m_k) \right\}. 
\end{equation}
For real values of  $u$ and $m_k$, this reduces to,



This is reassuring, because it suggests that for zero mean, additive IID gaussian noise, the most likely reference corresponds to minimizing the mean square error between the observation and reference. 

\subsection{One dimension, multi-channel}
We now consider a system where each of the reference $m_k$ consists of three one-dimensional vectors of length $N$, $m_{k1}$, $m_{k2}$ and $m_{k3}$ each in its own channel. Consequently, the signal $u$ now consists of a one dimensional observation $u_1$, $u_2$ and $u_3$ in each channel. As before, we assume $K$ references and that each channel has zero-mean additive IID gaussian noise, with variance $\sigma_1^2$,$\sigma_2^2$ and $\sigma_3^2$ respectively. As we will see later, these channels can be thought of as color channels in a hypothetical one dimensional composite red, green and blue image. 

We assert that three channels act independently, and thus the inverse probability that the observed signal $u$ is composed of the $k$th reference signal $m_k$ is simply the probability that $u_1$ is composed of $m_{k1}$ times the probability that $u_2$ is composed of $m_{k2}$ and similary for $u_3$ and $m_{k3}$
\begin{equation}
p(m_k|u)\sim p(u|m_k) = p(u_1|m_{k1})p(u_2|m_{k2})p(u_3|m_{k3})
\end{equation}

Substiting in from Eq.~\ref{eq:iidEnergy},

\begin{equation}
= \frac{1}{  \sqrt{ (2\pi)^{3N}} \sigma_1^N\sigma_2^N\sigma_3^N  } \exp\left\{ -\frac{(u-m_{k1})^T(u-m_{k1})} {2 N \sigma_1^2 }   - \frac{(u-m_{k2})^T(u-m_{k2})} {2 N \sigma_2^2 } -\frac{(u-m_{k3})^T(u-m_{k3})} {2 N \sigma_3^2 }    \right\}.
\end{equation}

You can convince yourself that these are independent because you can concatanate the three one-dimensional signals to create a vector of length $3N$. In that case..... Blah blah blah


Blah blah blah.

Now you can see that maximum likelihood model $k$ for $\Lambda_k$ correspond to,
\begin{equation}
\max_k   \big\{ p(m_k|u) \big\} =  \min_k  \left\{ (u_1-m_{k1})^T(u_1-m_{k1}) +  (u_2-m_{k2})^T(u_2-m_{k2}) +(u_3-m_{k3})^T(u_3-m_{k3}) \right\}. 
\end{equation}







%bold non-ital uppercase for matrices
%bold non-ital lowercase for vectors


%Walk through

\subsection{Garbage	} 

ASSUMPTION: The camera is just a photon counter. The noise we see comes overwhelmingly from "background fluorescence". We assume it is additive, thus we assume that our signal is merely superposed on top of the mean background. 

This implies that there is a single true peak height that is valid for all peaks. To test this assumption, I should background subtract the local mean from the barcodes and measure the height single isolated peaks. The height of locally background subtracted single isolated peaks should be flat and not correlate with location in the image.

This would mean that when identifying our barcode we don't have to scale our reference, we can use a single reference for all barcodes regardless of the location.


\section{Manuscript Information}
\subsection{Submitted for Publication As}
A version of this chapter has been submitted for publication in the journal \textit{Bioinformatics}.
% in \citep{leifer_optogenetic_2011}:
%\bibentry{leifer_optogenetic_2011}

\subsection{The Author's Contribution}
Andrew M.~Leifer wrote all of the software, generated all figures, developed portions of the mathematical framework, and wrote the majority of the manuscript. Mark C.~Leifer developed portions of the mathematical framework and wrote selected passages of the manuscript. Chenxiang Lin created the DNA origami barcodes and conducted all microscopy work. 
 